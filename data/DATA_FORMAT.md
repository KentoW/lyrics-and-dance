# Overview
This repository includes scripts for generating data related to pseudo lyrics and motions. Below are the details of each script's output.

## 1. Pseudo Lyrics Data (`generate_pseudo_lyrics.py`)
### Output Structure
When you run `generate_pseudo_lyrics.py`, it creates a directory named `lyrics_data` containing 100 `.joblib` files (`000.joblib` to `099.joblib`). Each file corresponds to a single song.

### File Content
Each `lyrics_data/*.joblib` file contains a nested list structure that represents:
- **Songs** → Divided into **bars** → Each bar further broken down into **frames**.
```python
[
    [
        [{'frame': 0, 'sentence': 'I love you', 'sentence_vector': array([...]), 'word': 'I', 'word_vector': array([...])}],
        [{'frame': 1, 'sentence': 'I love you', 'sentence_vector': array([...]), 'word': 'I', 'word_vector': array([...])}],
        ...
        [{'frame': 37, 'sentence': 'I love you', 'sentence_vector': array([...]), 'word': '[PAD]', 'word_vector': array([...])}],
    ],
    [
        [{'frame': 38, 'sentence': 'I miss you', 'sentence_vector': array([...]), 'word': 'I', 'word_vector': array([...])}],
        [{'frame': 39, 'sentence': 'I miss you', 'sentence_vector': array([...]), 'word': 'I', 'word_vector': array([...])}],
        ...
        [{'frame': 78, 'sentence': 'I miss you', 'sentence_vector': array([...]), 'word': 'you', 'word_vector': array([...])}],
    ], 
    ...
]
```

Each `lyrics_data4clustering/*.joblib` file contains lyrics vectors for k-means clustering:
```
[
    {'words':['I', 'love', 'you', '.'], 'sentence_vector': array([...]), 'word_vectors':[array([...]), array([...]),...]}, 
    {'words':['I', 'miss', 'you', '.'], 'sentence_vector': array([...]), 'word_vectors':[array([...]), array([...]),...]}, 
    ...
]
```

### Data Details
Each dictionary in the frame list contains the following keys:
- `frame`: The frame index within the song (assuming 30 FPS).
- `sentence`: The lyric sentence sung at the frame’s timestamp.
- `sentence_vector`: A Sentence-BERT embedding of the sentence.
- `word`: The lyric word sung at the frame’s timestamp.
- `word_vector`: A Sentence-BERT embedding of the word.
- `words`: List of words contained in a sentence.
- `word_vectors`: List of sentences-BERT embedding of words in a sentence.

If no lyrics are present at a given frame:
- The value of `sentence` and `word` is `[PAD]`.
- `sentence_vector` and `word_vector` are set to the Sentence-BERT embedding for the special token `[PAD]`.

### Why This Format?
This format captures every time frame in a song and maps it to the corresponding lyrics (both words and sentences) and their vector representations. It provides a complete view of the relationship between singing time and lyrical content.


## 2. Pseudo Motion Data (`generate_pseudo_motion.py`)

### Requirements
To run `generate_pseudo_motion.py`, you need the following files:
1. Lyrics Data: The pseudo lyrics data generated by `generate_pseudo_lyrics.py`.
2. Bone Structure Definitions:
    - `bone_names.json`: A list of joint names for the 3D human model.
    - `adjacency_dict.json`: An adjacency graph representing the connections between joints, where joints are nodes and bones are edges.
Refer to the JSON files for more details:
- `bone_names.json` contains the joint names as a list.
- `adjacency_dict.json` defines the adjacency relationships for the joints.
If you are using a custom 3D human model, you can edit these JSON files to match your model.

### Output Structure
Running `generate_pseudo_motion.py` creates the following outputs:
1. Motion Data:
    - A directory named `motion_data` containing 100 `.joblib` files (`000.joblib` to `099.joblib`).
    - Each `.joblib` file corresponds to one song and contains a list of dictionaries representing motion data for each bar.
    ```python
    [
        {"start_frame": 0, "skeletal_feature": array([...]), "affective_feature": array([...])},
        {"start_frame": 38, "skeletal_feature": array([...]), "affective_feature": array([...])},
        ...
    ]
    ```
2. Laplacian Positional Embedding:
    - A file named `lpe.joblib`, which stores the Laplacian positional embedding required for Graph Transformers.

### Data Details
Motion Data (`motion_data/XXX.joblib`)  
Each dictionary in the `.joblib` file represents motion data for a specific bar and contains the following keys:
- `start_frame`: The starting frame of the bar.
- `skeletal_feature`: 
    - A NumPy tensor with shape `(frame_length, bone_size, motion_parameter)`.
        - `frame_length`: The number of frames in the bar.
        - `bone_size`: The number of joints in the 3D human model. The order of joints in the `bone_size` dimension follows the sequence defined in `bone_names.json`.
        - `motion_parameter`: Includes XYZ coordinates, angles, joint positions, velocities, accelerations, etc. (See `generate_pseudo_motion.py` for details.)
    - **Normalization**: Values are normalized to the range [-1, 1].
- `affective_feature`:
    - A NumPy tensor with shape `(frame_length, feature_size)`.
        - `feature_size`: Includes hand-tuned features such as joint curvatures, body area, and volume. (See `generate_pseudo_motion.py` for details.)
    - **Normalization**: Values are normalized to the range [0, 1].

### Laplacian Positional Embedding (`lpe.joblib`)
This file contains Laplacian positional embeddings computed from the motion data, designed for use with Graph Transformers. These embeddings capture the spatial relationships of joints in the 3D human model.


## 3. Data Splitting (`split_train_dev_test.py`)

### Purpose
The `split_train_dev_test.py` script takes the outputs of `generate_pseudo_lyrics.py` and `generate_pseudo_motion.py` and splits them into three subsets:
- Training set
- Development set
- Testing set

These subsets are saved as JSONL files containing the absolute paths of the respective data files.

### Output Structure
Running the script generates the following files in the `instance` directory:
- `train.jsonl`
- `dev.jsonl`
- `test.jsonl`

Each file contains one JSON object per line, formatted as:
```json
{"song_id":"000", "lyrics": "/absolute/path/to/lyrics_data/000.joblib", "motion": "/absolute/path/to/motion_data/000.joblib"}
{"song_id":"001", "lyrics": "/absolute/path/to/lyrics_data/001.joblib", "motion": "/absolute/path/to/motion_data/001.joblib"}
...
```
### Usage of Output Files
These JSONL files are designed as input for scripts that train dance motion encoders. Each line provides the file paths to both the lyrics and motion data associated with the same song.

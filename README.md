# A Data-Driven Method for Analyzing and Quantifying Lyrics-Dance Motion Relationships ‚Äî Official PyTorch Implementation
**A Data-Driven Method for Analyzing and Quantifying Lyrics-Dance Motion Relationships (NAACL2025)**

Kento Watanabe,  Masataka Goto

*Abstract: Dancing to music with lyrics is a popular form of expression. While it is generally accepted that there are relationships between lyrics and dance motions, previous studies have not explored these relationships. A major challenge is that the relationships between lyrics and dance motions are not constant throughout a song, but are instead localized to specific parts. To address this challenge, we hypothesize that lyrics and dance motions that co-occur across multiple songs are related. Based on this hypothesis, we propose a novel data-driven method to detect the parts of songs where meaningful relationships between lyrics and dance motions exist. We use clustering to transform lyrics and dance motions into symbols, enabling the calculation of co-occurrence frequencies and detection of significant correlations.The effectiveness of our method is validated by a dataset of time-synchronized lyrics and dance motions, which showed high correlation values for emotionally salient lyrics such as "love", which is expressed in heart-shaped motions. Furthermore, using our relationship detection method, we propose a method for retrieving dance motions from lyrics that outperforms previous text-to-motion retrieval methods, which focus on prose and non-dance motions.*

# Important Notice üö®
This repository provides the following:
- **Training and evaluation scripts** for the deep learning model.
- **Details about the required training data format.**
- **A script for generating synthetic training data** for **verification purposes.**
### ‚ö†Ô∏è Training Data Not Included
Please note that **the training data is not included** in this repository. You must prepare your own training data separately. Ensure that your data matches the specified format to use the provided scripts effectively.

# Requirements
- Python 3.9
- PyTorch 
- transformers
- faiss-gpu
- networkx
- nltk
- scikit-learn
- scipy==1.6.0
- numpy==1.19.5
- gcc

# Getting Started

## 1. Generate Synthetic Training, Development and Test Data
To generate synthetic training and test data for verification purposes, run the following script:
```bash
python ./data/generate_pseudo_lyrics.py
python ./data/generate_pseudo_motion.py
python ./data/split_train_dev_test.py
```
For details about the required data format, refer to the documentation in: `./data/DATA_FORMAT.md`.

‚ö†Ô∏è **Important Note**: The data generated by these scripts consists of **random, meaningless numerical values** and does not represent actual motion data. Please do not use this data as a substitute for real-world motion datasets.

## 2. Train Dance Motion Encoder
The dance motion encoder is trained using time-synchronized dance motion and lyric data with the script below.
After the encoder is trained, the following script also calculates the dance motion vectors.
The motion vectors of the training data are stored in `motion_vector_train.joblib` and the motion vectors of the test data are stored in `motion_vector_test.joblib`.
```bash
python ./model/train.py
```

## 3. Convert Motion and Lyric Vectors into Codebooks
The obtained dance motion vectors and lyric vectors are clustered using K-means.  
Before running k-means, run `preprocess.py` to make duplicate sentences and motion vectors unique.
```bash
python ./codebook/preprocess.py
python ./codebook/clustering.py -LK 500 -MK 500
```
`LK` and `MK` are the codebook sizes for lyrics and motions respectively.

## 4. Evaluation of Lyrics-to-Dance Motion Retrieval
Finally, using the generated codebooks, dance motions are retrieved from lyrics.  
First, compile the C implementation of DTW calculation, as DTW will be used during retrieval, with the following command:
```bash
gcc -o dtw/dtw ./dtw/dtw.c -lpthread -lm
```
Next, run the retrieval and evaluation using the following script:
```bash
python ./experiment/decode_codebook.py
python ./experiment/calc_npmi.py
python ./experiment/l2d_retrieval.py
```
The results of the MRR will be included in the standard output and also in `experiment/result/sentence2motion_LK-0500_MK-0500/mrr.json`.  
(Here, `LK` is 500 and `MK` is 500 for the sentence to dance motion retrieval task.)

# Citation
```tex
@inproceedings{watanabe2025lyrics_and_dance,
    title        = {A Data-Driven Method for Analyzing and Quantifying Lyrics-Dance Motion Relationships}, 
    author       = {Kento Watanabe and Masataka Goto}, 
    booktitle    = {Proceedings of the 2025 Conference of the North American
                    Chapter of the Association for Computational Linguistics: 
                    Human Language Technologies, {NAACL} 2025},
    year         = {2025}
}
```
